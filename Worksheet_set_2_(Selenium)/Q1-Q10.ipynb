{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9df562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in d:\\datatrained\\anaconda\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
      "Requirement already satisfied: async-generator>=1.9 in d:\\datatrained\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\datatrained\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: idna in d:\\datatrained\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: sniffio in d:\\datatrained\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\datatrained\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in d:\\datatrained\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: pycparser in d:\\datatrained\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in d:\\datatrained\\anaconda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in d:\\datatrained\\anaconda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: certifi in d:\\datatrained\\anaconda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.5.2 in d:\\datatrained\\anaconda\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Installing collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.12.0 outcome-1.1.0 selenium-4.1.0 trio-0.19.0 trio-websocket-0.9.2 wsproto-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d25728",
   "metadata": {},
   "source": [
    "Now after successfully installing the selenium package we download the webdriver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc03f76",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6a18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e289a",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35f22a",
   "metadata": {},
   "source": [
    "Now, firstly we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b22f56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ff54b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1d203fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f8685",
   "metadata": {},
   "source": [
    "First thing to do is type the job position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d7e1777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"66c60542847221f3e7d5fde978b07f15\", element=\"18629279-c902-4ff0-92ac-e3d367440132\")>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We locate the position for where to input the search request using search_by_id\n",
    "job = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input\")\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "527427cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we input the word that is to be searched\n",
    "job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c2521",
   "metadata": {},
   "source": [
    "Now we move to the search location tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7cc15da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e77bfba0914904987b5f25d1d69857bc\", element=\"5caf5d46-c5e7-4429-baaa-1ac7478b89db\")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[2]/div/div/div/div[1]/div[2]/input')\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e4054c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we input the data we need to search\n",
    "loc.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac4471",
   "metadata": {},
   "source": [
    "Now, we seach for the search button and hit the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7ead040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e77bfba0914904987b5f25d1d69857bc\", element=\"afef6e56-c2cc-4989-8d8c-8195618c79cb\")>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btn = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button\")\n",
    "btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f3a7e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be0502",
   "metadata": {},
   "source": [
    "Now, he have reached the required page and start with the scraping of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3df36ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job Title is the first we scrape\n",
    "tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dccc1f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Safety Data Analyst',\n",
       " 'Lead - Data Analyst / Scientist',\n",
       " 'Research - Data Analyst / Associate',\n",
       " 'Data Analyst - CRM Platform',\n",
       " 'Senior Data Analyst - Supporting Audits',\n",
       " 'Senior Data Analyst - KPO',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Financial Data Analyst',\n",
       " 'Tcs Hiring For Data Analyst / Engineers']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        title.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bdae84",
   "metadata": {},
   "source": [
    "Now, we scrape the top 10 job locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab01e17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9939c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Delhi / NCR, Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Bangalore/Bengaluru, Delhi / NCR']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=[]\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        loc.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af60070",
   "metadata": {},
   "source": [
    "Now let us scrape the company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24a4ed91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fc4a5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Novo Nordisk India',\n",
       " 'Axim Technologies',\n",
       " 'AXL HR Tech',\n",
       " 'Artech infosystem',\n",
       " 'Visa',\n",
       " 'Huquo Consulting Pvt. Ltd',\n",
       " 'Multi Recruit',\n",
       " 'Snaphunt',\n",
       " \"Moody's\",\n",
       " 'TCS']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com = []\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        com.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b22590",
   "metadata": {},
   "source": [
    "Lastly, we scrape the experience required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e48cf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eef4d37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-4 Yrs',\n",
       " '12-14 Yrs',\n",
       " '0-2 Yrs',\n",
       " '1-6 Yrs',\n",
       " '5-8 Yrs',\n",
       " '7-12 Yrs',\n",
       " '2-4 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-2 Yrs',\n",
       " '4-9 Yrs']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = []\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        exp.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054bac4",
   "metadata": {},
   "source": [
    "Finally, we create a Dataframe for the scraped data and complete with the Question 1 of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8f32564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comapny</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Safety Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Novo Nordisk India</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Axim Technologies</td>\n",
       "      <td>12-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research - Data Analyst / Associate</td>\n",
       "      <td>Mumbai, Delhi / NCR, Bangalore/Bengaluru</td>\n",
       "      <td>AXL HR Tech</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst - Supporting Audits</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst - KPO</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Multi Recruit</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Snaphunt</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Moody's</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tcs Hiring For Data Analyst / Engineers</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TCS</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job Title  \\\n",
       "0                      Safety Data Analyst   \n",
       "1          Lead - Data Analyst / Scientist   \n",
       "2      Research - Data Analyst / Associate   \n",
       "3              Data Analyst - CRM Platform   \n",
       "4  Senior Data Analyst - Supporting Audits   \n",
       "5                Senior Data Analyst - KPO   \n",
       "6                             Data Analyst   \n",
       "7                             Data Analyst   \n",
       "8                   Financial Data Analyst   \n",
       "9  Tcs Hiring For Data Analyst / Engineers   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2           Mumbai, Delhi / NCR, Bangalore/Bengaluru   \n",
       "3  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9             Pune, Bangalore/Bengaluru, Delhi / NCR   \n",
       "\n",
       "                     Comapny Experience  \n",
       "0         Novo Nordisk India    0-4 Yrs  \n",
       "1          Axim Technologies  12-14 Yrs  \n",
       "2                AXL HR Tech    0-2 Yrs  \n",
       "3          Artech infosystem    1-6 Yrs  \n",
       "4                       Visa    5-8 Yrs  \n",
       "5  Huquo Consulting Pvt. Ltd   7-12 Yrs  \n",
       "6              Multi Recruit    2-4 Yrs  \n",
       "7                   Snaphunt    0-2 Yrs  \n",
       "8                    Moody's    0-2 Yrs  \n",
       "9                        TCS    4-9 Yrs  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job Title':title, 'Location':loc, 'Comapny':com, 'Experience':exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedce26f",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c18f4c",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad7d07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fc1f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa3e07",
   "metadata": {},
   "source": [
    "Calling the url to the selenium driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1752cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c24e53",
   "metadata": {},
   "source": [
    "Entering the designation into the bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28c819f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"15e063100411b76c02f0ffcd39a684ae\", element=\"49b3b375-f335-490b-b612-4c8e5fc3bfea\")>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[1]/div/div/div/div[1]/div[2]/input')\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ec73eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3597a09",
   "metadata": {},
   "source": [
    "Now, we locate and enter the location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ba1cdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"15e063100411b76c02f0ffcd39a684ae\", element=\"ec64a2f9-cb08-43ff-ba40-a1d4d82b12f8\")>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[2]/div/div/div/div[1]/div[2]/input')\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db6666c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ae23c",
   "metadata": {},
   "source": [
    "Locating the search button and clicking it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd1caf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"15e063100411b76c02f0ffcd39a684ae\", element=\"dab89057-7eea-434b-90ab-66759fad2d57\")>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button')\n",
    "btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea6a12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecdd585",
   "metadata": {},
   "source": [
    "Scraping the job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf585850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68572326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead/Senior Data Scientist (NLP)',\n",
       " 'Commercial Analytics Data Scientist',\n",
       " 'Senior Data Scientist - Logistics',\n",
       " 'Lead Data Scientist - NLP/OpenCV',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist - Prescriptive Analytics/Predictive Modeling',\n",
       " 'Lead - Data Analyst / Scientist',\n",
       " 'Data scientist ( WFH )',\n",
       " 'Hiring For Data Scientist @ Bangalore',\n",
       " 'Data Scientist - Logistics']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        title.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c6dd2",
   "metadata": {},
   "source": [
    "Scraping the job location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1d1dc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67da29b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=[]\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        loc.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6641de0",
   "metadata": {},
   "source": [
    "Scraping company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0208c25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b7c1281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Samya.AI A FRACTAL Entity',\n",
       " 'Dell',\n",
       " 'GO-JEK India',\n",
       " 'Codersbrain',\n",
       " 'First American',\n",
       " 'Codersbrain',\n",
       " 'Axim Technologies',\n",
       " 'SPM Jobs',\n",
       " 'West Pharmaceutical Packaging India Pvt. Ltd.',\n",
       " 'Gojek Tech']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp = []\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        cmp.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ecbaea",
   "metadata": {},
   "source": [
    "Finally, we create a Dataframe for the scraped data and complete with the Question 1 of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4165e04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comapny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead/Senior Data Scientist (NLP)</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Samya.AI A FRACTAL Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commercial Analytics Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - Logistics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GO-JEK India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist - NLP/OpenCV</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Codersbrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>First American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist - Prescriptive Analytics/P...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Codersbrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Axim Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data scientist ( WFH )</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SPM Jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For Data Scientist @ Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>West Pharmaceutical Packaging India Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Logistics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                   Lead/Senior Data Scientist (NLP)   \n",
       "1                Commercial Analytics Data Scientist   \n",
       "2                  Senior Data Scientist - Logistics   \n",
       "3                   Lead Data Scientist - NLP/OpenCV   \n",
       "4                                Lead Data Scientist   \n",
       "5  Lead Data Scientist - Prescriptive Analytics/P...   \n",
       "6                    Lead - Data Analyst / Scientist   \n",
       "7                             Data scientist ( WFH )   \n",
       "8              Hiring For Data Scientist @ Bangalore   \n",
       "9                         Data Scientist - Logistics   \n",
       "\n",
       "                                      Location  \\\n",
       "0      Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "1                          Bangalore/Bengaluru   \n",
       "2                          Bangalore/Bengaluru   \n",
       "3  Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "4                          Bangalore/Bengaluru   \n",
       "5  Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "6                          Bangalore/Bengaluru   \n",
       "7                          Bangalore/Bengaluru   \n",
       "8      Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "9                          Bangalore/Bengaluru   \n",
       "\n",
       "                                         Comapny  \n",
       "0                      Samya.AI A FRACTAL Entity  \n",
       "1                                           Dell  \n",
       "2                                   GO-JEK India  \n",
       "3                                    Codersbrain  \n",
       "4                                 First American  \n",
       "5                                    Codersbrain  \n",
       "6                              Axim Technologies  \n",
       "7                                       SPM Jobs  \n",
       "8  West Pharmaceutical Packaging India Pvt. Ltd.  \n",
       "9                                     Gojek Tech  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job Title':title, 'Location':loc, 'Comapny':cmp})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86081561",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "# You have to use the location and salary filter.\n",
    "# You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "# You have to scrape the job-title, job-location, company name, experience required.\n",
    "# The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d4040",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "02cd35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ffc7a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e26d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7117d0",
   "metadata": {},
   "source": [
    "Enter the job designation to the search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "143aa2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fa2e565333de051ef84798e4d8808abb\", element=\"d6de80b2-344a-420f-bf87-3822ff4dc5e5\")>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "90885b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499d2a6",
   "metadata": {},
   "source": [
    "Locating the search button and clicking search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e3faa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fa2e565333de051ef84798e4d8808abb\", element=\"29ab02ed-46e5-4b9b-a892-8e0fb1855841\")>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f7c520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308e465",
   "metadata": {},
   "source": [
    "Applying the location filter to Delhi/NCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "918dd2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fa2e565333de051ef84798e4d8808abb\", element=\"ec7976f0-037b-45e0-8580-14c48d291899\")>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_loc = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "fil_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a8bc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_loc.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01208b99",
   "metadata": {},
   "source": [
    "Applying salary filter of 3-6 lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd5b6094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fa2e565333de051ef84798e4d8808abb\", element=\"76158781-d2c4-4d81-9395-e4cd0bf49ac5\")>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ff198d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8729453",
   "metadata": {},
   "source": [
    "Scraping job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e1394088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3745ca64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist | Python | Machine Learning | Deep Learning- Fresher',\n",
       " 'Senior Data Scientist I',\n",
       " 'Openings For Jr/mid/Sr level data Scientists',\n",
       " 'Urgent Hiring For Data Scientist',\n",
       " 'Urgent Hiring For Data Scientist',\n",
       " 'Data Scientist role',\n",
       " 'Data Scientist role',\n",
       " 'Data Scientist Internship',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        title.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f40b2b",
   "metadata": {},
   "source": [
    "Scraping job location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1c753100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78d68075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)\\n(WFH during Covid)',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR\\n(WFH during Covid)',\n",
       " 'Noida, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR\\n(WFH during Covid)',\n",
       " 'New Delhi',\n",
       " 'Noida, New Delhi, Faridabad, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Chennai']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = []\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        loc.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad6abf",
   "metadata": {},
   "source": [
    "Scraping Company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41a19710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c1b53b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Schlesinger Group',\n",
       " 'Delhivery',\n",
       " 'Pluto seven business solutions (p) limited',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'iHackers Inc',\n",
       " 'LG',\n",
       " 'Teleperformance']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp = []\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        cmp.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abae6d",
   "metadata": {},
   "source": [
    "Scraping experience required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dddcd11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "16d362eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '3-7 Yrs',\n",
       " '2-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-3 Yrs',\n",
       " '1-3 Yrs',\n",
       " '0-1 Yrs',\n",
       " '0-2 Yrs',\n",
       " '4-9 Yrs']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = []\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        exp.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24510dd",
   "metadata": {},
   "source": [
    "Finally, making a DataFrame for all the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9d86e461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comapny</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Schlesinger Group</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Openings For Jr/mid/Sr level data Scientists</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Pluto seven business solutions (p) limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>iHackers Inc</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...</td>\n",
       "      <td>LG</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Chennai</td>\n",
       "      <td>Teleperformance</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Data Scientist | Python | Machine Learning | D...   \n",
       "1                            Senior Data Scientist I   \n",
       "2       Openings For Jr/mid/Sr level data Scientists   \n",
       "3                   Urgent Hiring For Data Scientist   \n",
       "4                   Urgent Hiring For Data Scientist   \n",
       "5                                Data Scientist role   \n",
       "6                                Data Scientist role   \n",
       "7                          Data Scientist Internship   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "3              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "4              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "6  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "7                                          New Delhi   \n",
       "8  Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...   \n",
       "9                          Gurgaon/Gurugram, Chennai   \n",
       "\n",
       "                                      Comapny Experience  \n",
       "0                           Schlesinger Group    0-3 Yrs  \n",
       "1                                   Delhivery    3-7 Yrs  \n",
       "2  Pluto seven business solutions (p) limited    2-6 Yrs  \n",
       "3     Mount Talent Consulting Private Limited    1-6 Yrs  \n",
       "4     Mount Talent Consulting Private Limited    1-6 Yrs  \n",
       "5     Mount Talent Consulting Private Limited    1-3 Yrs  \n",
       "6     Mount Talent Consulting Private Limited    1-3 Yrs  \n",
       "7                                iHackers Inc    0-1 Yrs  \n",
       "8                                          LG    0-2 Yrs  \n",
       "9                             Teleperformance    4-9 Yrs  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job Title':title, 'Location':loc, 'Comapny':cmp, 'Experience':exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d73f7a",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "## 1. Brand\n",
    "## 2. Product Description\n",
    "## 3. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec89f0",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dae3577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f1eb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a68a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e003f9",
   "metadata": {},
   "source": [
    "Closing the login popup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d020c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9f1a5",
   "metadata": {},
   "source": [
    "Locating the search tab and inputting 'sunglasses' to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "771bacaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a79c1771f71972669b9bb1fe6358aca2\", element=\"a5d44287-2995-4d2d-b89d-6645bbec2b8f\")>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52e59028",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34184f9e",
   "metadata": {},
   "source": [
    "Loacting and clicking search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23d8c5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a79c1771f71972669b9bb1fe6358aca2\", element=\"8bfaf71e-4b20-46ec-861d-40ac3d46b13a\")>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "665a8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88002219",
   "metadata": {},
   "source": [
    "First we define empty elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f44eb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnd = []\n",
    "prd = []\n",
    "prc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce6527",
   "metadata": {},
   "source": [
    "Now, we start scraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82fdbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1=o2=o3=0\n",
    "\n",
    "tag1 = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in tag1:\n",
    "    if(o1<100):\n",
    "        bnd.append(i.text)\n",
    "        o1+=1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "tag2 = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in tag2:\n",
    "    if(o2<100):\n",
    "        prd.append(i.text)\n",
    "        o2+=1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "tag3 = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in tag3:\n",
    "    if(o3<100):\n",
    "        prc.append(i.text)\n",
    "        o3+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d31411",
   "metadata": {},
   "source": [
    "Check whether we have scraped 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53a92386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(bnd),len(prd),len(prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b728b67",
   "metadata": {},
   "source": [
    "Since, we have to scrape more data from next page. Clicking the next button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3fd46a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn1 = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "btn1.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3211c89c",
   "metadata": {},
   "source": [
    "Scraping the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4128f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag1 = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in tag1:\n",
    "    if(o1<100):\n",
    "        bnd.append(i.text)\n",
    "        o1+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "tag2 = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in tag2:\n",
    "    if(o2<100):\n",
    "        prd.append(i.text)\n",
    "        o2+=1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "tag3 = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in tag3:\n",
    "    if(o3<100):\n",
    "        prc.append(i.text)\n",
    "        o3+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605a71c",
   "metadata": {},
   "source": [
    "Check whether we have scraped 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df132648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(bnd),len(prd),len(prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419517ef",
   "metadata": {},
   "source": [
    "Since, we have to scrape more data from next page. Clicking the next button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da104828",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b5f11",
   "metadata": {},
   "source": [
    "Scraping the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d61bee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag1 = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in tag1:\n",
    "    if(o1<100):\n",
    "        bnd.append(i.text)\n",
    "        o1+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "tag2 = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in tag2:\n",
    "    if(o2<100):\n",
    "        prd.append(i.text)\n",
    "        o2+=1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "tag3 = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in tag3:\n",
    "    if(o3<100):\n",
    "        prc.append(i.text)\n",
    "        o3+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cb59c",
   "metadata": {},
   "source": [
    "Check whether we have scraped 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d72ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(bnd),len(prd),len(prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1a4d2",
   "metadata": {},
   "source": [
    "Since, we have scraped 100 data as required. We finish with the solution by making a DataFrame of the data scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70448084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Shield Sung...</td>\n",
       "      <td>₹426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Poloport</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description Price\n",
       "0    VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (53)  ₹999\n",
       "1    VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (...  ₹999\n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹759\n",
       "3             SRPM             UV Protection Wayfarer Sunglasses (56)  ₹188\n",
       "4        Elligator                UV Protection Round Sunglasses (54)  ₹248\n",
       "..             ...                                                ...   ...\n",
       "95  ROZZETTA CRAFT  UV Protection, Gradient Butterfly, Shield Sung...  ₹426\n",
       "96      PHENOMENAL  UV Protection Retro Square Sunglasses (Free Size)  ₹309\n",
       "97        Poloport      UV Protection Wayfarer Sunglasses (Free Size)  ₹236\n",
       "98          PIRASO       UV Protection Aviator Sunglasses (Free Size)  ₹261\n",
       "99  ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...  ₹349\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand Name':bnd, 'Product Description':prd, 'Price':prc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932aabb",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9027f586",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3475f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c712b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4abc0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eef82c",
   "metadata": {},
   "source": [
    "Clicking on the all reviews section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fccf826",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ed335",
   "metadata": {},
   "source": [
    "Initializing the empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb5f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtg = []\n",
    "smr = []\n",
    "des = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f838c9f",
   "metadata": {},
   "source": [
    "Scraping data from page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7aacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1=o2=o3=0\n",
    "tag1 = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in tag1:\n",
    "    if(o1<100):\n",
    "        rtg.append(i.text)\n",
    "        o1+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "tag2 = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in tag2:\n",
    "    if(o2<100):\n",
    "        smr.append(i.text)\n",
    "        o2+=1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "tag3 = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in tag3:\n",
    "    if(o3<100):\n",
    "        des.append(i.text)\n",
    "        o3+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1f974",
   "metadata": {},
   "source": [
    "Checking the amount of data scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c9f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rtg),len(smr),len(des))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82546e",
   "metadata": {},
   "source": [
    "We click on the button next to scrape more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe047fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436eb306",
   "metadata": {},
   "source": [
    "Now, we scrape the complete data using a loop for faster working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cce25e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing exception library to counter Stale Element Reference\n",
    "from selenium.common import exceptions\n",
    "\n",
    "for j in range(0,10):\n",
    "    try:\n",
    "        # We scrape the data\n",
    "        tag1 = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in tag1:\n",
    "            if(o1<100):\n",
    "                rtg.append(i.text)\n",
    "                o1+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "        tag2 = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in tag2:\n",
    "            if(o2<100):\n",
    "                smr.append(i.text)\n",
    "                o2+=1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        tag3 = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in tag3:\n",
    "            if(o3<100):\n",
    "                des.append(i.text)\n",
    "                o3+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "        # We check if we need more data, if yes we click the next button for next page\n",
    "        if(o1<100):\n",
    "            a = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "            a.click()\n",
    "    except exceptions.StaleElementReferenceException:\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02b1b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rtg),len(smr),len(des))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e40f3e",
   "metadata": {},
   "source": [
    "We finally create a Dataframe for the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66bdad74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description Summary</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Totally in love with this ❤ the camera quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Description Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5     Perfect product!   \n",
       "3       5  Best in the market!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5       Classy product   \n",
       "97      5       Simply awesome   \n",
       "98      5    Worth every penny   \n",
       "99      5    Worth every penny   \n",
       "\n",
       "                                          Description  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Iphone is just awesome.. battery backup is ver...  \n",
       "96  It's my first time to use iOS phone and I am l...  \n",
       "97  Best budget Iphone till date ❤️ go for it guys...  \n",
       "98  Totally in love with this ❤ the camera quality...  \n",
       "99  Excellent camera, good performance, no lag. Th...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rating':rtg, 'Description Summary':smr, 'Description':des})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd3638",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415740b9",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8c0a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a0ad5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c84a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ea314",
   "metadata": {},
   "source": [
    "First, we close the login popup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ec141cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b8657a",
   "metadata": {},
   "source": [
    "Now, we enter the search data into the search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20aa5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "tag.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e30baa",
   "metadata": {},
   "source": [
    "Now, we click on the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dca54ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11460604",
   "metadata": {},
   "source": [
    "Initializing empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f86190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "brd = []\n",
    "des = []\n",
    "prc = []\n",
    "off = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce35d2",
   "metadata": {},
   "source": [
    "Now, we start scraping the data. We use loop for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2170c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1=o2=o3=0\n",
    "while o1 < 100:\n",
    "    try:\n",
    "        # We scrape the data\n",
    "        tag1 = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/div[1]')\n",
    "        for i in tag1:\n",
    "            if(o1<100):\n",
    "                brd.append(i.text)\n",
    "                o1+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "        tag2 = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[1]')\n",
    "        for i in tag2:\n",
    "            if(o2<100):\n",
    "                des.append(i.text)\n",
    "                o2+=1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        tag3 = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for i in tag3:\n",
    "            if(o3<100):\n",
    "                prc.append(i.text)\n",
    "                o3+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "        # We check if we need more data, if yes we click the next button for next page\n",
    "        if(o1<100):\n",
    "            a = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "            a.click()\n",
    "    except exceptions.StaleElementReferenceException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a5893",
   "metadata": {},
   "source": [
    "We check if we have scraped the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ab794ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brd),len(des),len(prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b70463",
   "metadata": {},
   "source": [
    "We create a DataFrame for the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35d0a9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOC</td>\n",
       "      <td>Luxury Fashionable Breathable Casual Sneakers ...</td>\n",
       "      <td>₹417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Stylish &amp; Trendy Sneakers For Men</td>\n",
       "      <td>₹630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Brothers Luxury Fashionable Men's Casual Walki...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DUNKASTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HOC</td>\n",
       "      <td>Series 7 Sneakers For Men</td>\n",
       "      <td>₹444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Stylish &amp; Trendy Sneakers For Men</td>\n",
       "      <td>₹620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price\n",
       "0              HOC  Luxury Fashionable Breathable Casual Sneakers ...  ₹417\n",
       "1         RapidBox                  Stylish & Trendy Sneakers For Men  ₹630\n",
       "2         Magnolia                                   Sneakers For Men  ₹398\n",
       "3   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...  ₹449\n",
       "4         URBANBOX                          Sneakers Sneakers For Men  ₹220\n",
       "..             ...                                                ...   ...\n",
       "95           SPARX  Brothers Luxury Fashionable Men's Casual Walki...  ₹449\n",
       "96       DUNKASTON                                   Sneakers For Men  ₹298\n",
       "97             HOC                          Series 7 Sneakers For Men  ₹444\n",
       "98        RapidBox                                   Sneakers For Men  ₹189\n",
       "99        Magnolia                  Stylish & Trendy Sneakers For Men  ₹620\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand':brd, 'Description':des, 'Price':prc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c42297",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes. Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”. And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c321e",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9996c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a877d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.myntra.com/shoes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "200f4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc6d02",
   "metadata": {},
   "source": [
    "Setting the colour filter 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6069da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fdbcca",
   "metadata": {},
   "source": [
    "Setting the price filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81b5704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34da830",
   "metadata": {},
   "source": [
    "Setting empty lists to scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5893102",
   "metadata": {},
   "outputs": [],
   "source": [
    "brd = []\n",
    "des = []\n",
    "prc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e267b",
   "metadata": {},
   "source": [
    "Now, we start scraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f2c6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1=o2=o3=0\n",
    "while o1 < 100:\n",
    "    try:\n",
    "        # We scrape the data\n",
    "        tag1 = driver.find_elements_by_xpath('//div[@class=\"product-productMetaInfo\"]/h3[1]')\n",
    "        for i in tag1:\n",
    "            if(o1<100):\n",
    "                brd.append(i.text)\n",
    "                o1+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "        tag2 = driver.find_elements_by_xpath('//div[@class=\"product-productMetaInfo\"]/h4[1]')\n",
    "        for i in tag2:\n",
    "            if(o2<100):\n",
    "                des.append(i.text)\n",
    "                o2+=1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        tag3 = driver.find_elements_by_xpath('//div[@class=\"product-price\"]/span[1]')\n",
    "        for i in tag3:\n",
    "            if(o3<100):\n",
    "                prc.append(i.text.split('Rs.')[1])\n",
    "                o3+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "        # We check if we need more data, if yes we click the next button for next page\n",
    "        if(o1<100):\n",
    "            a = driver.find_element_by_xpath('//li[@class=\"pagination-next\"]')\n",
    "            a.click()\n",
    "    except exceptions.StaleElementReferenceException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb883bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brd),len(des),len(prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f91a0",
   "metadata": {},
   "source": [
    "Now, we make a DataFrame for the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd23b140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes F1 Sneakers</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Magnify Nitro Running</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Electrify Nitro Running</td>\n",
       "      <td>7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Men Mid-Top Chelsea Boots</td>\n",
       "      <td>9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Magnify Nitro Shoes</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MANGO</td>\n",
       "      <td>Suede Block Heeled Boots</td>\n",
       "      <td>10350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ECCO</td>\n",
       "      <td>Striped Suede Flatform Heeled Boots</td>\n",
       "      <td>8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>PEAKFREAK XCRSN Trekking Shoe</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MANGO</td>\n",
       "      <td>Women REDMOND V2 TrekkingShoe</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Perforations Sneakers</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                          Description   Price\n",
       "0   PUMA Motorsport          Unisex Mercedes F1 Sneakers    7999\n",
       "1              Puma            Men Magnify Nitro Running    8449\n",
       "2              Puma          Men Electrify Nitro Running    7499\n",
       "3           Saint G            Men Mid-Top Chelsea Boots    9810\n",
       "4              Puma            Women Magnify Nitro Shoes    8449\n",
       "..              ...                                  ...     ...\n",
       "95            MANGO             Suede Block Heeled Boots   10350\n",
       "96             ECCO  Striped Suede Flatform Heeled Boots    8910\n",
       "97             Puma        PEAKFREAK XCRSN Trekking Shoe    9999\n",
       "98            MANGO        Women REDMOND V2 TrekkingShoe    7999\n",
       "99   Tommy Hilfiger          Women Perforations Sneakers    8999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand':brd, 'Description':des, 'Price':prc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6deea",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "# Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”. After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "## 1. Title\n",
    "## 2. Ratings\n",
    "## 3. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28155b9",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f13a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e03a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.in/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "735e8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728bdcf5",
   "metadata": {},
   "source": [
    "Inseting 'Laptop' in search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b938765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "lbl.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f444cb8",
   "metadata": {},
   "source": [
    "Pressing the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01bdb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82801512",
   "metadata": {},
   "source": [
    "Pressing see more to show complete filter list for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d25103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/div/div/div[1]/div/span[2]/a')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c58af",
   "metadata": {},
   "source": [
    "Pressing i7 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "292e3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/div/div/div[1]/div/span[1]/a[11]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a73155",
   "metadata": {},
   "source": [
    "Initializing empty array and scraping title name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b3eda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty array\n",
    "title = []\n",
    "\n",
    "# Scraping title name\n",
    "tags = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        title.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b374e4",
   "metadata": {},
   "source": [
    "Initializing empty array and scraping price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78816883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty array\n",
    "prc = []\n",
    "\n",
    "# Scraping title name\n",
    "tags = driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "b=0\n",
    "for i in tags:\n",
    "    if(b<10):\n",
    "        prc.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a105f0",
   "metadata": {},
   "source": [
    "Initializing empty array and scraping rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba80aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting urls of all laptops\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-link-style a-text-normal']\")\n",
    "\n",
    "UR=[]\n",
    "rating = []\n",
    "\n",
    "# Getting the url of first 10 laptops\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "\n",
    "#loop for every laptop in the list\n",
    "for url in UR:\n",
    "    driver.get(url)\n",
    "    #exception handling for nosuchelementexception \n",
    "    try:                           \n",
    "        r=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\") #locating the rating\n",
    "        rating.append(r.text) #appending the ratings in Ratings list\n",
    "    except :\n",
    "        rating.append(\"NO rating\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c1068",
   "metadata": {},
   "source": [
    "Check whether all the required data has been scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc46266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(rating),len(prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22920c8",
   "metadata": {},
   "source": [
    "Creating a DataFrame for all the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ddff80ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>4.7 out of 5</td>\n",
       "      <td>95,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LG Gram 17-inches Ultra-Light Intel Evo 11th G...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Legion 5 11th Gen Intel Core i7 15.6\"(3...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>1,00,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Rating     Price\n",
       "0  Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...  4.7 out of 5    95,490\n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5    57,990\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...    5 out of 5    59,990\n",
       "3  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...  4.5 out of 5    89,990\n",
       "4  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...  4.3 out of 5    79,990\n",
       "5  HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...  4.6 out of 5    86,990\n",
       "6  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5    57,990\n",
       "7  LG Gram 17-inches Ultra-Light Intel Evo 11th G...  4.6 out of 5    99,990\n",
       "8  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...  4.1 out of 5    82,990\n",
       "9  Lenovo Legion 5 11th Gen Intel Core i7 15.6\"(3...  4.3 out of 5  1,00,490"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':title, 'Rating':rating, 'Price':prc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae350544",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32131fa",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4d1f1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1fc32118",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ambitionbox.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "697f8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374746b",
   "metadata": {},
   "source": [
    "Clicking of the 'jobs' option on the menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c371827",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcd577",
   "metadata": {},
   "source": [
    "Giving Data Scientist as the search feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1f294812",
   "metadata": {},
   "outputs": [],
   "source": [
    "srch = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input')\n",
    "srch.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a4d30",
   "metadata": {},
   "source": [
    "Clicking search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "848cb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/button')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35890801",
   "metadata": {},
   "source": [
    "Clicking on location filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "69954354",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac245f",
   "metadata": {},
   "source": [
    "Searching for noida in location by inserting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d8e444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "srch = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "srch.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6483260",
   "metadata": {},
   "source": [
    "Selecting the noida filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "118e33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19e69d",
   "metadata": {},
   "source": [
    "Now, we scrape the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "151ef727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an empty list\n",
    "cmp = []\n",
    "\n",
    "# Scraping data into the list\n",
    "tag = driver.find_elements_by_xpath('//div[@class=\"company-info\"]/p')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b>0 & b<11):\n",
    "        cmp.append(i.text)\n",
    "    b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "204ede99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an empty list\n",
    "day = []\n",
    "\n",
    "# Scraping data into the list\n",
    "tag = driver.find_elements_by_xpath('//div[@class=\"other-info\"]/span[1]')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b<10):\n",
    "        day.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8722f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an empty list\n",
    "rat = []\n",
    "\n",
    "# Scraping data into the list\n",
    "tag = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b<10):\n",
    "        rat.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e09d4",
   "metadata": {},
   "source": [
    "Checking if we have scraped the required amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "21a724f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(cmp),len(day),len(rat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc789446",
   "metadata": {},
   "source": [
    "Creating a DataFrame for the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "edf1df89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Day to Advertisement</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nokia Solutions and Networks India (P)Ltd.</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ameriprise Financial</td>\n",
       "      <td>3hr ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RMS Risk Management Solutions</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Company Day to Advertisement Rating\n",
       "0  Nokia Solutions and Networks India (P)Ltd.              12d ago    4.3\n",
       "1                        Ameriprise Financial              3hr ago    4.0\n",
       "2                                       Paytm               6d ago    3.7\n",
       "3                  Jubilant Foodworks Limited              23d ago    3.9\n",
       "4                                CHT Sapiense               7d ago    3.7\n",
       "5                                CHT Sapiense               8d ago    3.7\n",
       "6                                    GI Group              19d ago    4.1\n",
       "7                                    GI Group              19d ago    4.1\n",
       "8                                    GI Group              19d ago    4.1\n",
       "9               RMS Risk Management Solutions               1d ago    3.5"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Company':cmp, 'Day to Advertisement':day, 'Rating':rat})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a425be",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868b346",
   "metadata": {},
   "source": [
    "Firstly, we connect to the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e35dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\jjjib\\Desktop\\Projects\\FlipRobo\\Web Scrapping 14-01\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29bf124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ambitionbox.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18686c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b88c8",
   "metadata": {},
   "source": [
    "Clicking on Salary option on menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "769a7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf6b20",
   "metadata": {},
   "source": [
    "We put 'Data Scientist' as search feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5bc9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "srch = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "srch.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038baa0",
   "metadata": {},
   "source": [
    "Clicking on Data Scientist drop down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aad26f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.implicitly_wait(10)\n",
    "btn = driver.find_element_by_xpath('//div[@class=\"tt-dataset tt-dataset-job-profile-search\"]/div[1]')\n",
    "ActionChains(driver).move_to_element(btn).click(btn).perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9164e",
   "metadata": {},
   "source": [
    "Now, we start scraping the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59e5e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty array\n",
    "cmp = []\n",
    "\n",
    "# Scraping data\n",
    "tag = driver.find_elements_by_xpath('//div[@class=\"name\"]/a')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b<10):\n",
    "        cmp.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2ead35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty array\n",
    "tot = []\n",
    "\n",
    "# Scraping data\n",
    "tag = driver.find_elements_by_xpath('//div[@class=\"name\"]/span')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b<10):\n",
    "        tot.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c0e6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty array\n",
    "exp = []\n",
    "\n",
    "# Scraping data\n",
    "tag = driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b<10):\n",
    "        exp.append(i.text.split('\\n')[2])\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16456ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty array\n",
    "mini = []\n",
    "maxi = []\n",
    "\n",
    "# Scraping data\n",
    "tag = driver.find_elements_by_xpath('//div[@class=\"salary-values\"]')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b<10):\n",
    "        mini.append(i.text.split('\\n')[0])\n",
    "        maxi.append(i.text.split('\\n')[1])\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "248a6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty array\n",
    "avg = []\n",
    "\n",
    "# Scraping data\n",
    "tag = driver.find_elements_by_xpath('//div[@class=\"average-indicator-wrapper\"]/p')\n",
    "b=0\n",
    "for i in tag:\n",
    "    if(b<10):\n",
    "        avg.append(i.text)\n",
    "        b+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711878a",
   "metadata": {},
   "source": [
    "Now, we check if we have scraped all the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea5619ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(cmp),len(tot),len(exp),len(mini),len(maxi),len(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d874463",
   "metadata": {},
   "source": [
    "Now, we form a DataFrame for the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ec97740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>3 yrs exp</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 28.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 72 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 42 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company   Total Salary Record   Experience Minimum Salary  \\\n",
       "0                   Walmart  based on 10 salaries    3 yrs exp        ₹ 17.7L   \n",
       "1                  Ab Inbev  based on 22 salaries  3-4 yrs exp        ₹ 15.0L   \n",
       "2                        ZS  based on 14 salaries    2 yrs exp         ₹ 9.8L   \n",
       "3         Fractal Analytics  based on 72 salaries  2-4 yrs exp         ₹ 9.5L   \n",
       "4                     Optum  based on 23 salaries  3-4 yrs exp        ₹ 11.0L   \n",
       "5              UnitedHealth  based on 49 salaries  2-4 yrs exp         ₹ 7.2L   \n",
       "6           Tiger Analytics  based on 27 salaries  3-4 yrs exp         ₹ 8.3L   \n",
       "7                   Verizon  based on 14 salaries    4 yrs exp        ₹ 10.0L   \n",
       "8  Ganit Business Solutions  based on 13 salaries    4 yrs exp         ₹ 8.5L   \n",
       "9                  Ericsson  based on 42 salaries  3-4 yrs exp         ₹ 5.8L   \n",
       "\n",
       "  Average Salary Maximum Salary  \n",
       "0        ₹ 28.7L        ₹ 35.0L  \n",
       "1        ₹ 19.5L        ₹ 25.0L  \n",
       "2        ₹ 15.8L        ₹ 20.0L  \n",
       "3        ₹ 15.0L        ₹ 22.0L  \n",
       "4        ₹ 15.0L        ₹ 21.3L  \n",
       "5        ₹ 13.5L        ₹ 20.5L  \n",
       "6        ₹ 13.5L        ₹ 18.5L  \n",
       "7        ₹ 12.7L        ₹ 21.0L  \n",
       "8        ₹ 12.4L        ₹ 15.0L  \n",
       "9        ₹ 11.9L        ₹ 21.5L  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Company':cmp, 'Total Salary Record':tot, 'Experience':exp, 'Minimum Salary':mini, 'Average Salary':avg, 'Maximum Salary':maxi})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65bc618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
